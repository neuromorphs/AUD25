{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab7fd939-ad91-488b-963a-70af0bafc96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Preproccess EEG data from BrainVision\n",
    "Saves in .mat format, segmented by triggers\n",
    "\"\"\"\n",
    "\n",
    "################\n",
    "## Imports\n",
    "################\n",
    "import mne\n",
    "import os\n",
    "import glob\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import savemat\n",
    "from scipy.signal import hilbert, resample, correlate\n",
    "from scipy.signal import butter, filtfilt\n",
    "import matplotlib.pyplot as plt\n",
    "import naplib as nl\n",
    "\n",
    "from IPython.display import Audio, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "789b996e-5a51-49b4-add7-dac2eb83dcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowpass_filter(data, cutoff, fs, order=4):\n",
    "    b, a = butter(order, cutoff / (0.5 * fs), btype='low')\n",
    "    return filtfilt(b, a, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4569faf4-631b-452c-8f29-5c7889a1b97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_i = 3\n",
    "stimuli_list = ['../../Stimuli/Cindy/speech_only_long_22kHz/jane_eyre_05_part1.wav',\n",
    "               '../../Stimuli/Cindy/piano_only_long_22kHz/piano_4_1_22050Hz.wav',\n",
    "               '../../Stimuli/Cindy/speech_only_long_22kHz/jane_eyre_05_part2.wav',\n",
    "               '../../Stimuli/Cindy/piano_only_long_22kHz/piano_4_2_22050Hz.wav']\n",
    "# stimuli_sr = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b4299c2-109d-4f31-9467-aee9c993ef35",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## EDIT THIS PART\n",
    "################\n",
    "\n",
    "# file = '../EEG_data_test/trig_test_2/Untitled2.vhdr'\n",
    "file = f'../../Data/Samet/single{stim_i+1}.vhdr'\n",
    "\n",
    "filename = file.split('/')[-1].split('.')[0]\n",
    "exp_type = file.split('/')[-1].split('.')[0].split('_')[-1]\n",
    "# exp_type = 'mixed' \n",
    "\n",
    "output_dir = '../../Data/Samet/Preprocessed/preprocessed_single_01_15Hz'\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "overwrite = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fb0daeb-711f-48ae-b383-59af2f869fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "################\n",
    "## Parameters\n",
    "################\n",
    "plot = False\n",
    "# FS_ORIG = 25000  # Hz\n",
    "\n",
    "# Preprocessing\n",
    "# Notch filtering\n",
    "notch_applied = False\n",
    "freq_notch = 60\n",
    "\n",
    "# Bandpass filtering\n",
    "bpf_applied = True\n",
    "freq_low   = 0.1\n",
    "freq_high  = 15\n",
    "bandpass = str(freq_low) + '-' + str(freq_high)\n",
    "ftype = 'butter'\n",
    "order = 3\n",
    "\n",
    "# Spherical interpolation\n",
    "int_applied = False\n",
    "interpolation = 'spline'\n",
    "\n",
    "# Rereferencing using average of mastoids electrodes\n",
    "reref_applied = True\n",
    "reref_type = 'average'  #channels or average\n",
    "reref_channels = None\n",
    "\n",
    "# Downsampling\n",
    "down_applied = True\n",
    "downfreq = 128\n",
    "if not down_applied:\n",
    "    downfreq = 'N/A'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebdb8a5-b393-45f0-9e3e-fb3b41c8c729",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from ../../Data/Samet/single4.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 561779  =      0.000 ...   561.779 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p8/sfp3f3z124xdkgdf3ksb_kp00000gn/T/ipykernel_5422/1919079818.py:4: RuntimeWarning: No coordinate information found for channels ['Soundwave']. Setting channel types to misc. To avoid this warning, set channel types explicitly.\n",
      "  raw = mne.io.read_raw_brainvision(file, preload=True)\n",
      "/var/folders/p8/sfp3f3z124xdkgdf3ksb_kp00000gn/T/ipykernel_5422/1919079818.py:4: RuntimeWarning: Not setting position of 1 misc channel found in montage:\n",
      "['Soundwave']\n",
      "Consider setting the channel types to be of EEG/sEEG/ECoG/DBS/fNIRS using inst.set_channel_types before calling inst.set_montage, or omit these channels when creating your montage.\n",
      "  raw = mne.io.read_raw_brainvision(file, preload=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['New Segment/', 'Stimulus/S  3']\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## Read and crop data\n",
    "################\n",
    "raw = mne.io.read_raw_brainvision(file, preload=True)\n",
    "\n",
    "#get info from raw\n",
    "FS_ORIG = raw.info['sfreq']\n",
    "ch_names = raw.ch_names\n",
    "events, event_id = mne.events_from_annotations(raw)\n",
    "\n",
    "#crop to start\n",
    "trial_start = events[0][0] / FS_ORIG\n",
    "trial_end = raw.times[-1]\n",
    "eeg = raw.copy().crop(tmin = trial_start,\n",
    "                      tmax = trial_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d2f03fc-9bd1-430b-aa07-9adeac8915b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match found at index range: 5132 to 556467\n",
      "4973\n"
     ]
    }
   ],
   "source": [
    "# Load long audio at 1000 Hz\n",
    "long_audio = eeg.get_data()[31,:]\n",
    "long_sr = 1000\n",
    "\n",
    "# Load short audio at its native rate (22050 Hz)\n",
    "stimname = stimuli_list[stim_i].split('/')[-1][:-4]\n",
    "if stim_i in [0,2]:\n",
    "    short_audio, short_sr = librosa.load(f'../../Stimuli/Cindy/speech_only_long_22kHz/{stimname}.wav', sr=None)\n",
    "elif stim_i in [1,3]:\n",
    "    short_audio, short_sr = librosa.load(f'../../Stimuli/Cindy/piano_only_long_22kHz/{stimname}.wav', sr=None)\n",
    "    \n",
    "\n",
    "# Resample short audio to match long audio's sampling rate\n",
    "short_audio_resampled = librosa.resample(short_audio, orig_sr=short_sr, target_sr=long_sr)\n",
    "\n",
    "# Normalize both signals\n",
    "long_audio = (long_audio - np.mean(long_audio)) / np.std(long_audio)\n",
    "short_audio_resampled = (short_audio_resampled - np.mean(short_audio_resampled)) / np.std(short_audio_resampled)\n",
    "\n",
    "# Cross-correlation to find best match\n",
    "correlation = correlate(long_audio, short_audio_resampled, mode='valid')\n",
    "best_match_index = np.argmax(correlation)\n",
    "end_index = best_match_index + len(short_audio_resampled)\n",
    "\n",
    "print(f\"Best match found at index range: {best_match_index} to {end_index}\")\n",
    "print(events[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981e85c6-e380-48e3-b0e9-67c1878651f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Setting up band-pass filter from 0.1 - 15 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 12 (effective, after forward-backward)\n",
      "- Cutoffs at 0.10, 15.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 0.1 - 15 Hz\n",
      "\n",
      "IIR filter parameters\n",
      "---------------------\n",
      "Butterworth bandpass zero-phase (two-pass forward and reverse) non-causal filter:\n",
      "- Filter order 12 (effective, after forward-backward)\n",
      "- Cutoffs at 0.10, 15.00 Hz: -6.02, -6.02 dB\n",
      "\n",
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n",
      "<Info | 9 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fz, F3, F7, FT9, FC5, FC1, C3, T7, TP9, CP5, CP1, Pz, P3, ...\n",
      " chs: 31 EEG\n",
      " custom_ref_applied: True\n",
      " dig: 34 items (3 Cardinal, 31 EEG)\n",
      " highpass: 0.1 Hz\n",
      " lowpass: 15.0 Hz\n",
      " meas_date: 2025-07-10 11:10:32 UTC\n",
      " nchan: 31\n",
      " projs: []\n",
      " sfreq: 128.0 Hz\n",
      ">\n",
      "single4_piano_4_2_22050Hz.mat\n"
     ]
    }
   ],
   "source": [
    "################\n",
    "## SEGMENT DATA\n",
    "################\n",
    "\n",
    "eeg = raw.copy().crop(tmin=best_match_index / FS_ORIG, tmax = end_index / FS_ORIG)\n",
    "\n",
    "################\n",
    "## Preprocess\n",
    "################\n",
    "df_pre = pd.DataFrame()\n",
    "\n",
    "## -------------\n",
    "## Select channels\n",
    "## -------------\n",
    "eeg_channels = ch_names[0:31]\n",
    "eeg = eeg.pick_channels(eeg_channels)\n",
    "if plot:\n",
    "    eeg.plot(start=100, duration=10, n_channels=len(raw.ch_names))\n",
    "\n",
    "## -------------\n",
    "## Notch filtering\n",
    "## -------------\n",
    "df_pre['notch_applied'] = [notch_applied]\n",
    "if notch_applied:\n",
    "    eeg = eeg.notch_filter(freqs=freq_notch)\n",
    "    df_pre['notch'] = [freq_notch]\n",
    "    if plot:\n",
    "        eeg.plot()\n",
    "\n",
    "## -------------\n",
    "## BPFiltering\n",
    "## -------------\n",
    "df_pre['bpf_applied'] = [bpf_applied]\n",
    "if bpf_applied:\n",
    "    iir_params = dict(order=order, ftype=ftype)\n",
    "    filter_params = mne.filter.create_filter(eeg.get_data(), eeg.info['sfreq'], \n",
    "                                            l_freq=freq_low, h_freq=freq_high, \n",
    "                                            method='iir', iir_params=iir_params)\n",
    "\n",
    "    if plot:\n",
    "        flim = (1., eeg.info['sfreq'] / 2.)  # frequencies\n",
    "        dlim = (-0.001, 0.001)  # delays\n",
    "        kwargs = dict(flim=flim, dlim=dlim)\n",
    "        mne.viz.plot_filter(filter_params, eeg.info['sfreq'], compensate=True, **kwargs)\n",
    "        # plt.savefig(os.path.join(output_dir, 'bpf_ffilt_shape.png'))\n",
    "\n",
    "    eeg = eeg.filter(l_freq=freq_low, h_freq=freq_high, method='iir', iir_params=iir_params)\n",
    "    df_pre['bandpass'] = [iir_params]\n",
    "    df_pre['HPF'] = [freq_low]\n",
    "    df_pre['LPF'] = [freq_high]\n",
    "    if plot:\n",
    "        eeg.plot()\n",
    "\n",
    "## -------------\n",
    "## Intrpolation\n",
    "## -------------\n",
    "df_pre['int_applied'] = [int_applied]\n",
    "if int_applied: \n",
    "    eeg = eeg.interpolate_bads(reset_bads=False)  #, method=interpolation\n",
    "\n",
    "    # Get the indices and names of the interpolated channels\n",
    "    interp_inds = eeg.info['bads']\n",
    "    interp_names = [eeg.info['ch_names'][i] for i in interp_inds]\n",
    "\n",
    "    # Print the number and names of the interpolated channels\n",
    "    print(f'{len(interp_inds)} channels interpolated: {interp_names}')\n",
    "\n",
    "    df_pre['interpolation'] = [interpolation]\n",
    "    df_pre['interp_inds'] = [interp_inds]\n",
    "    df_pre['interp_names'] = [interp_names]\n",
    "\n",
    "    if plot:\n",
    "        eeg.plot()\n",
    "\n",
    "## -------------\n",
    "## Rereferencing\n",
    "## -------------\n",
    "df_pre['reref_applied'] = [reref_applied]\n",
    "if reref_applied:\n",
    "    if reref_type == 'average':\n",
    "        # reref to average\n",
    "        eeg = eeg.set_eeg_reference(ref_channels='average')\n",
    "        df_pre['reref_type'] = [reref_type]\n",
    "        df_pre['reref_channels'] = ['average']\n",
    "        if plot:\n",
    "            eeg.plot()\n",
    "\n",
    "    elif reref_type == 'channels':\n",
    "        # reref to a channel\n",
    "        eeg = eeg.set_eeg_reference(ref_channels=reref_channels)\n",
    "        df_pre['reref_type'] = [reref_type]\n",
    "        df_pre['reref_channels'] = [reref_channels]\n",
    "        if plot:\n",
    "            eeg.plot()\n",
    "\n",
    "## -------------\n",
    "## Resampling\n",
    "## -------------\n",
    "df_pre['down_applied'] = [down_applied]\n",
    "df_pre['downfreq'] = [downfreq]\n",
    "if down_applied:\n",
    "    eeg = eeg.resample(sfreq=downfreq)\n",
    "    print(eeg.info)\n",
    "    if plot:\n",
    "        eeg.plot()\n",
    "\n",
    "## -------------\n",
    "## Stimuli\n",
    "## -------------\n",
    "curr_audio, sr = short_audio, short_sr\n",
    "analytic_signal = hilbert(curr_audio)\n",
    "envelope = np.abs(analytic_signal)\n",
    "\n",
    "cutoff_freq = 8  # Hz\n",
    "envelope = lowpass_filter(envelope, cutoff=cutoff_freq, fs=short_sr)\n",
    "\n",
    "# _, envelope, _ = nl.preprocessing.filter_hilbert(curr_audio, stimuli_sr)\n",
    "# envelope = np.squeeze(envelope)\n",
    "\n",
    "duration_sec = len(envelope) / short_sr\n",
    "n_target_samples = int(duration_sec * downfreq)\n",
    "\n",
    "envelope = resample(envelope, n_target_samples)\n",
    "\n",
    "## -------------\n",
    "## Save preprocessing stages\n",
    "## -------------\n",
    "df_pre.to_csv(os.path.join(output_dir, filename+'_pp_record.csv'), index=False)\n",
    "\n",
    "\n",
    "################\n",
    "## Save files\n",
    "################\n",
    "\n",
    "eeg_tosave = eeg.get_data()\n",
    "savename = filename + '_' + stimname +'.mat'\n",
    "print(savename)\n",
    "savemat(os.path.join(output_dir, savename), \n",
    "        #{'eeg_data': eeg_tosave[0:31]}\n",
    "        {'eeg_data': eeg_tosave, 'stimuli': short_audio, 'envelope': envelope}\n",
    "        )\n",
    "\n",
    "#segment single to 10 mins\n",
    "#else: \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cu)",
   "language": "python",
   "name": "cu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
