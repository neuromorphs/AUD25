{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8dcdc3f-bf4f-4554-9a67-2d48262955e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import mtrf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import Audio, display\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import linalg\n",
    "from scipy import stats\n",
    "from scipy.signal import hilbert, resample, correlate\n",
    "from scipy.stats import zscore, pearsonr\n",
    "\n",
    "from mtrf.model import TRF\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "593b6220-8568-44af-91ca-5bc99f048e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_generator_new(r, lags):\n",
    "    '''\n",
    "    Args:\n",
    "      r: [time, neurons]\n",
    "      \n",
    "    Return\n",
    "      out: [time, neuron*lags]\n",
    "    \n",
    "    '''\n",
    "    lags = list(range(lags[0], lags[1]+1))\n",
    "    out = np.zeros([r.shape[0], r.shape[1]*len(lags)])\n",
    "    r = np.pad(r, ((0,len(lags)),(0,0)), 'constant')\n",
    "\n",
    "    r_lag_list = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        t1 = np.roll(r, lag, axis=0)\n",
    "        if lag < 0:\n",
    "            t1[lag-1:, :] = 0\n",
    "        else:\n",
    "            t1[:lag, :] = 0\n",
    "            \n",
    "        r_lag_list.append(t1[:out.shape[0], :])\n",
    "        \n",
    "    out = np.concatenate(r_lag_list, axis=1)\n",
    "    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f7a4bc-5ee0-4da0-9007-dd26a2d7031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trials = os.listdir('../../../Data/Cindy/Preprocessed/preprocessed_mixed_new')\n",
    "#trials.remove('cindy_mixed_pp_record.csv')\n",
    "\n",
    "folder_name = '../../../Data/Cindy/Preprocessed/preprocessed_mixed_01_30Hz'\n",
    "trials = os.listdir(folder_name)\n",
    "trials = [item for item in trials if item not in ['cindy_mixed_pp_record.csv','.ipynb_checkpoints.mat','.ipynb_checkpoints']]\n",
    "\n",
    "\n",
    "# folder_name = '../../../Data/Samet/Preprocessed/preprocessed_mixed_01_15Hz'\n",
    "# trials = os.listdir(folder_name)\n",
    "# trials = [item for item in trials if item not in ['multi1_pp_record.csv','multi2_pp_record.csv','multi3_pp_record.csv','multi4_pp_record.csv','.ipynb_checkpoints.mat','.ipynb_checkpoints']]\n",
    "\n",
    "fs_eeg = 128\n",
    "\n",
    "lags_neuro = [-40, 10]\n",
    "lags_stim = [-10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52b09784-ebeb-4cb1-978f-4d83ce2d32c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cindy_mixed_Music_32.mat\n",
      "cindy_mixed_Music_26.mat\n",
      "cindy_mixed_Music_27.mat\n",
      "cindy_mixed_Music_33.mat\n",
      "cindy_mixed_Music_25.mat\n",
      "cindy_mixed_Music_31.mat\n",
      "cindy_mixed_Music_19.mat\n",
      "cindy_mixed_Music_18.mat\n",
      "cindy_mixed_Music_30.mat\n",
      "cindy_mixed_Music_24.mat\n",
      "cindy_mixed_Music_20.mat\n",
      "cindy_mixed_Music_34.mat\n",
      "cindy_mixed_Music_35.mat\n",
      "cindy_mixed_Music_21.mat\n",
      "cindy_mixed_Music_37.mat\n",
      "cindy_mixed_Music_23.mat\n",
      "cindy_mixed_Music_22.mat\n",
      "cindy_mixed_Music_36.mat\n",
      "cindy_mixed_Music_8.mat\n",
      "cindy_mixed_Speech_1.mat\n",
      "Best match found at index range: 3969000 to 5292000 (Corr: 1734870.75)\n",
      "cindy_mixed_Speech_17.mat\n",
      "Best match found at index range: 104004956 to 105327956 (Corr: 1941546.375)\n",
      "cindy_mixed_Speech_16.mat\n",
      "Best match found at index range: 100035956 to 101358956 (Corr: 1572415.875)\n",
      "cindy_mixed_Speech_0.mat\n",
      "Best match found at index range: 1323000 to 2646000 (Corr: 1772553.875)\n",
      "cindy_mixed_Music_9.mat\n",
      "cindy_mixed_Speech_2.mat\n",
      "Best match found at index range: 5292000 to 6615000 (Corr: 1696999.75)\n",
      "cindy_mixed_Speech_14.mat\n",
      "Best match found at index range: 96066956 to 97389956 (Corr: 1682389.5)\n",
      "cindy_mixed_Speech_28.mat\n",
      "Best match found at index range: 23814001 to 25137001 (Corr: 1846089.625)\n",
      "cindy_mixed_Speech_29.mat\n",
      "Best match found at index range: 85482956 to 86805956 (Corr: 1781639.75)\n",
      "cindy_mixed_Speech_15.mat\n",
      "Best match found at index range: 97389956 to 98712956 (Corr: 1903243.125)\n",
      "cindy_mixed_Speech_3.mat\n",
      "Best match found at index range: 9261000 to 10584000 (Corr: 1190234.0)\n",
      "cindy_mixed_Speech_7.mat\n",
      "Best match found at index range: 19845001 to 21168001 (Corr: 1842736.625)\n",
      "cindy_mixed_Speech_11.mat\n",
      "Best match found at index range: 88128956 to 89451956 (Corr: 1596560.125)\n",
      "cindy_mixed_Speech_10.mat\n",
      "Best match found at index range: 84159956 to 85482956 (Corr: 1087492.125)\n",
      "cindy_mixed_Speech_6.mat\n",
      "Best match found at index range: 15876001 to 17199001 (Corr: 1915513.75)\n",
      "cindy_mixed_Speech_4.mat\n",
      "Best match found at index range: 11907000 to 13230000 (Corr: 1691669.5)\n",
      "cindy_mixed_Speech_12.mat\n",
      "Best match found at index range: 90774956 to 92097956 (Corr: 1774320.75)\n",
      "cindy_mixed_Speech_13.mat\n",
      "Best match found at index range: 92097956 to 93420956 (Corr: 1169271.0)\n",
      "cindy_mixed_Speech_5.mat\n",
      "Best match found at index range: 13230000 to 14553000 (Corr: 1098550.0)\n",
      "cindy_mixed_Music_1.mat\n",
      "cindy_mixed_Speech_8.mat\n",
      "Best match found at index range: 22491001 to 23814001 (Corr: 1612999.5)\n",
      "cindy_mixed_Speech_36.mat\n",
      "Best match found at index range: 102681956 to 104004956 (Corr: 1934272.75)\n",
      "cindy_mixed_Speech_22.mat\n",
      "Best match found at index range: 7938000 to 9261000 (Corr: 1804597.25)\n",
      "cindy_mixed_Speech_23.mat\n",
      "Best match found at index range: 10584000 to 11907000 (Corr: 1696001.875)\n",
      "cindy_mixed_Speech_37.mat\n",
      "Best match found at index range: 105327956 to 106650956 (Corr: 1565162.125)\n",
      "cindy_mixed_Speech_9.mat\n",
      "Best match found at index range: 25137001 to 26460001 (Corr: 2011275.25)\n",
      "cindy_mixed_Music_0.mat\n",
      "cindy_mixed_Music_2.mat\n",
      "cindy_mixed_Speech_21.mat\n",
      "Best match found at index range: 6615000 to 7938000 (Corr: 1746917.875)\n",
      "cindy_mixed_Speech_35.mat\n",
      "Best match found at index range: 101358956 to 102681956 (Corr: 1698505.375)\n",
      "cindy_mixed_Speech_34.mat\n",
      "Best match found at index range: 98712956 to 100035956 (Corr: 755231.0625)\n",
      "cindy_mixed_Speech_20.mat\n",
      "Best match found at index range: 2646000 to 3969000 (Corr: 1085320.0)\n",
      "cindy_mixed_Music_3.mat\n",
      "cindy_mixed_Music_7.mat\n",
      "cindy_mixed_Speech_18.mat\n",
      "Best match found at index range: 106650956 to 107973956 (Corr: 1766727.625)\n",
      "cindy_mixed_Speech_24.mat\n",
      "Best match found at index range: 14553001 to 15876001 (Corr: 1501283.5)\n",
      "cindy_mixed_Speech_30.mat\n",
      "Best match found at index range: 86805956 to 88128956 (Corr: 1791733.125)\n",
      "cindy_mixed_Speech_31.mat\n",
      "Best match found at index range: 89451956 to 90774956 (Corr: 2250071.75)\n",
      "cindy_mixed_Speech_25.mat\n",
      "Best match found at index range: 17199001 to 18522001 (Corr: 938666.1875)\n",
      "cindy_mixed_Speech_19.mat\n",
      "Best match found at index range: 0 to 1323000 (Corr: 1818167.0)\n",
      "cindy_mixed_Music_6.mat\n",
      "cindy_mixed_Music_4.mat\n",
      "cindy_mixed_Speech_33.mat\n",
      "Best match found at index range: 94743956 to 96066956 (Corr: 1397754.25)\n",
      "cindy_mixed_Speech_27.mat\n",
      "Best match found at index range: 21168001 to 22491001 (Corr: 1252690.75)\n",
      "cindy_mixed_Speech_26.mat\n",
      "Best match found at index range: 18522001 to 19845001 (Corr: 1636085.625)\n",
      "cindy_mixed_Speech_32.mat\n",
      "Best match found at index range: 93420956 to 94743956 (Corr: 1492583.875)\n",
      "cindy_mixed_Music_5.mat\n",
      "cindy_mixed_Music_13.mat\n",
      "cindy_mixed_Music_12.mat\n",
      "cindy_mixed_Music_10.mat\n",
      "cindy_mixed_Music_11.mat\n",
      "cindy_mixed_Music_29.mat\n",
      "cindy_mixed_Music_15.mat\n",
      "cindy_mixed_Music_14.mat\n",
      "cindy_mixed_Music_28.mat\n",
      "cindy_mixed_Music_16.mat\n",
      "cindy_mixed_Music_17.mat\n"
     ]
    }
   ],
   "source": [
    "speech_eeg_all = []\n",
    "# speech_att_env_all = []\n",
    "# speech_unatt_env_all = []\n",
    "\n",
    "speech_unatt_surprisal_all = []\n",
    "\n",
    "# Load long audio\n",
    "long_audio, long_sr = librosa.load(f'../../../Stimuli/Cindy/piano_4.wav', sr=None)\n",
    "\n",
    "surprisal_feature = pd.read_csv('../../../Stimuli/Cindy/Surprisal/piano_4.csv')\n",
    "surprisal_feature = np.array(surprisal_feature['surprise'].to_list())\n",
    "\n",
    "for trial in trials:\n",
    "    print(trial)\n",
    "    data = loadmat(os.path.join(folder_name,trial))\n",
    "    \n",
    "    if data['stim_attended'][0] == 'Speech':\n",
    "        att_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/speech_only_short_22khz\",f\"{data['stimuli_speech'][0]}\"+'.wav'))\n",
    "        unatt_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/piano_only_long_cropped_22khz\",f\"{data['stimuli_music'][0]}\"+'.wav'))\n",
    "    elif data['stim_attended'][0] == 'Music':\n",
    "        continue\n",
    "        att_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/piano_only_long_cropped_22khz\",f\"{data['stimuli_music'][0]}\"+'.wav'))\n",
    "        unatt_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/speech_only_short_22khz\",f\"{data['stimuli_speech'][0]}\"+'.wav'))\n",
    "        \n",
    "    \n",
    "    if data['stim_attended_pos'][0] == 'FirstHalfAttend':\n",
    "        att_stim = att_stim[:int(len(att_stim)/2)]\n",
    "        unatt_stim = unatt_stim[:int(len(unatt_stim)/2)]\n",
    "    elif data['stim_attended_pos'][0] == 'SecondHalfAttend':\n",
    "        att_stim = att_stim[int(len(att_stim)/2):]\n",
    "        unatt_stim = unatt_stim[int(len(unatt_stim)/2):]\n",
    "    \n",
    "    # Load short audio at its native rate (22050 Hz)\n",
    "    short_audio = np.squeeze(unatt_stim)\n",
    "    short_sr = 22050\n",
    "    \n",
    "    # Resample short audio to match long audio's sampling rate\n",
    "    short_audio_resampled = librosa.resample(short_audio, orig_sr=short_sr, target_sr=long_sr)\n",
    "    \n",
    "    # Normalize both signals\n",
    "    long_audio = (long_audio - np.mean(long_audio)) / np.std(long_audio)\n",
    "    short_audio_resampled = (short_audio_resampled - np.mean(short_audio_resampled)) / np.std(short_audio_resampled)\n",
    "    \n",
    "    # Cross-correlation to find best match\n",
    "    correlation = correlate(long_audio, short_audio_resampled, mode='valid')\n",
    "    best_match_index = np.argmax(correlation)\n",
    "    end_index = best_match_index + len(short_audio_resampled)\n",
    "\n",
    "    print(f\"Best match found at index range: {best_match_index} to {end_index} (Corr: {np.max(correlation)})\")\n",
    "\n",
    "    unatt_surprisal = np.expand_dims(surprisal_feature[round((best_match_index/long_sr*128)):round((end_index/long_sr*128))],axis=0)\n",
    "    \n",
    "    # att_env = np.abs(hilbert(att_stim))\n",
    "    # unatt_env = np.abs(hilbert(unatt_stim))\n",
    "    \n",
    "    # duration_sec = len(att_env) / fs_audio\n",
    "    # n_target_samples = int(duration_sec * fs_eeg)\n",
    "    # att_env = np.expand_dims(resample(att_env, n_target_samples),axis=0)\n",
    "    \n",
    "    # duration_sec = len(unatt_env) / fs_audio\n",
    "    # n_target_samples = int(duration_sec * fs_eeg)\n",
    "    # unatt_env = np.expand_dims(resample(unatt_env, n_target_samples),axis=0)\n",
    "\n",
    "    speech_eeg_all.append(data['eeg_data'])\n",
    "    speech_unatt_surprisal_all.append(unatt_surprisal)\n",
    "    # speech_att_env_all.append(att_env)\n",
    "    # speech_unatt_env_all.append(unatt_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "945c4789-f5bb-4ada-827b-025c3a3b4195",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cindy_mixed_Music_32.mat\n",
      "Best match found at index range: 92097956 to 93420956 (Corr: 1169271.0)\n",
      "cindy_mixed_Music_26.mat\n",
      "Best match found at index range: 19845001 to 21168001 (Corr: 1842736.625)\n",
      "cindy_mixed_Music_27.mat\n",
      "Best match found at index range: 22491001 to 23814001 (Corr: 1612999.5)\n",
      "cindy_mixed_Music_33.mat\n",
      "Best match found at index range: 96066956 to 97389956 (Corr: 1682389.5)\n",
      "cindy_mixed_Music_25.mat\n",
      "Best match found at index range: 15876001 to 17199001 (Corr: 1915513.75)\n",
      "cindy_mixed_Music_31.mat\n",
      "Best match found at index range: 90774956 to 92097956 (Corr: 1774320.75)\n",
      "cindy_mixed_Music_19.mat\n",
      "Best match found at index range: 1323000 to 2646000 (Corr: 1772553.875)\n",
      "cindy_mixed_Music_18.mat\n",
      "Best match found at index range: 105327956 to 106650956 (Corr: 1565162.125)\n",
      "cindy_mixed_Music_30.mat\n",
      "Best match found at index range: 88128956 to 89451956 (Corr: 1596560.125)\n",
      "cindy_mixed_Music_24.mat\n",
      "Best match found at index range: 13230000 to 14553000 (Corr: 1098550.0)\n",
      "cindy_mixed_Music_20.mat\n",
      "Best match found at index range: 3969000 to 5292000 (Corr: 1734871.375)\n",
      "cindy_mixed_Music_34.mat\n",
      "Best match found at index range: 97389956 to 98712956 (Corr: 1903243.125)\n",
      "cindy_mixed_Music_35.mat\n",
      "Best match found at index range: 100035956 to 101358956 (Corr: 1572415.875)\n",
      "cindy_mixed_Music_21.mat\n",
      "Best match found at index range: 5292000 to 6615000 (Corr: 1696999.75)\n",
      "cindy_mixed_Music_37.mat\n",
      "Best match found at index range: 106650956 to 107973956 (Corr: 1766727.625)\n",
      "cindy_mixed_Music_23.mat\n",
      "Best match found at index range: 11907000 to 13230000 (Corr: 1691669.5)\n",
      "cindy_mixed_Music_22.mat\n",
      "Best match found at index range: 9261000 to 10584000 (Corr: 1190234.0)\n",
      "cindy_mixed_Music_36.mat\n",
      "Best match found at index range: 104004956 to 105327956 (Corr: 1941546.625)\n",
      "cindy_mixed_Music_8.mat\n",
      "Best match found at index range: 21168001 to 22491001 (Corr: 1252690.75)\n",
      "cindy_mixed_Speech_1.mat\n",
      "cindy_mixed_Speech_17.mat\n",
      "cindy_mixed_Speech_16.mat\n",
      "cindy_mixed_Speech_0.mat\n",
      "cindy_mixed_Music_9.mat\n",
      "Best match found at index range: 23814001 to 25137001 (Corr: 1846089.625)\n",
      "cindy_mixed_Speech_2.mat\n",
      "cindy_mixed_Speech_14.mat\n",
      "cindy_mixed_Speech_28.mat\n",
      "cindy_mixed_Speech_29.mat\n",
      "cindy_mixed_Speech_15.mat\n",
      "cindy_mixed_Speech_3.mat\n",
      "cindy_mixed_Speech_7.mat\n",
      "cindy_mixed_Speech_11.mat\n",
      "cindy_mixed_Speech_10.mat\n",
      "cindy_mixed_Speech_6.mat\n",
      "cindy_mixed_Speech_4.mat\n",
      "cindy_mixed_Speech_12.mat\n",
      "cindy_mixed_Speech_13.mat\n",
      "cindy_mixed_Speech_5.mat\n",
      "cindy_mixed_Music_1.mat\n",
      "Best match found at index range: 2646000 to 3969000 (Corr: 1085320.0)\n",
      "cindy_mixed_Speech_8.mat\n",
      "cindy_mixed_Speech_36.mat\n",
      "cindy_mixed_Speech_22.mat\n",
      "cindy_mixed_Speech_23.mat\n",
      "cindy_mixed_Speech_37.mat\n",
      "cindy_mixed_Speech_9.mat\n",
      "cindy_mixed_Music_0.mat\n",
      "Best match found at index range: 0 to 1323000 (Corr: 1818167.0)\n",
      "cindy_mixed_Music_2.mat\n",
      "Best match found at index range: 6615000 to 7938000 (Corr: 1746917.875)\n",
      "cindy_mixed_Speech_21.mat\n",
      "cindy_mixed_Speech_35.mat\n",
      "cindy_mixed_Speech_34.mat\n",
      "cindy_mixed_Speech_20.mat\n",
      "cindy_mixed_Music_3.mat\n",
      "Best match found at index range: 7938000 to 9261000 (Corr: 1804597.25)\n",
      "cindy_mixed_Music_7.mat\n",
      "Best match found at index range: 18522001 to 19845001 (Corr: 1636085.625)\n",
      "cindy_mixed_Speech_18.mat\n",
      "cindy_mixed_Speech_24.mat\n",
      "cindy_mixed_Speech_30.mat\n",
      "cindy_mixed_Speech_31.mat\n",
      "cindy_mixed_Speech_25.mat\n",
      "cindy_mixed_Speech_19.mat\n",
      "cindy_mixed_Music_6.mat\n",
      "Best match found at index range: 17199001 to 18522001 (Corr: 938666.1875)\n",
      "cindy_mixed_Music_4.mat\n",
      "Best match found at index range: 10584000 to 11907000 (Corr: 1696002.0)\n",
      "cindy_mixed_Speech_33.mat\n",
      "cindy_mixed_Speech_27.mat\n",
      "cindy_mixed_Speech_26.mat\n",
      "cindy_mixed_Speech_32.mat\n",
      "cindy_mixed_Music_5.mat\n",
      "Best match found at index range: 14553001 to 15876001 (Corr: 1501283.5)\n",
      "cindy_mixed_Music_13.mat\n",
      "Best match found at index range: 93420956 to 94743956 (Corr: 1492583.875)\n",
      "cindy_mixed_Music_12.mat\n",
      "Best match found at index range: 89451956 to 90774956 (Corr: 2250071.75)\n",
      "cindy_mixed_Music_10.mat\n",
      "Best match found at index range: 85482956 to 86805956 (Corr: 1781639.75)\n",
      "cindy_mixed_Music_11.mat\n",
      "Best match found at index range: 86805956 to 88128956 (Corr: 1791733.125)\n",
      "cindy_mixed_Music_29.mat\n",
      "Best match found at index range: 84159956 to 85482956 (Corr: 1087492.125)\n",
      "cindy_mixed_Music_15.mat\n",
      "Best match found at index range: 98712956 to 100035956 (Corr: 755231.0625)\n",
      "cindy_mixed_Music_14.mat\n",
      "Best match found at index range: 94743956 to 96066956 (Corr: 1397754.25)\n",
      "cindy_mixed_Music_28.mat\n",
      "Best match found at index range: 25137001 to 26460001 (Corr: 2011275.25)\n",
      "cindy_mixed_Music_16.mat\n",
      "Best match found at index range: 101358956 to 102681956 (Corr: 1698505.625)\n",
      "cindy_mixed_Music_17.mat\n",
      "Best match found at index range: 102681956 to 104004956 (Corr: 1934272.5)\n"
     ]
    }
   ],
   "source": [
    "music_eeg_all = []\n",
    "# music_att_env_all = []\n",
    "# music_unatt_env_all = []\n",
    "\n",
    "music_att_surprisal_all = []\n",
    "\n",
    "for trial in trials:\n",
    "    print(trial)\n",
    "    data = loadmat(os.path.join(folder_name,trial))\n",
    "    \n",
    "    if data['stim_attended'][0] == 'Speech':\n",
    "        continue\n",
    "        att_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/speech_only_short_22khz\",f\"{data['stimuli_speech'][0]}\"+'.wav'))\n",
    "        unatt_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/piano_only_long_cropped_22khz\",f\"{data['stimuli_music'][0]}\"+'.wav'))\n",
    "    elif data['stim_attended'][0] == 'Music':\n",
    "        att_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/piano_only_long_cropped_22khz\",f\"{data['stimuli_music'][0]}\"+'.wav'))\n",
    "        unatt_stim,fs_audio = librosa.load(os.path.join(\"../../../Stimuli/Cindy/speech_only_short_22khz\",f\"{data['stimuli_speech'][0]}\"+'.wav'))\n",
    "        \n",
    "    \n",
    "    if data['stim_attended_pos'][0] == 'FirstHalfAttend':\n",
    "        att_stim = att_stim[:int(len(att_stim)/2)]\n",
    "        unatt_stim = unatt_stim[:int(len(unatt_stim)/2)]\n",
    "    elif data['stim_attended_pos'][0] == 'SecondHalfAttend':\n",
    "        att_stim = att_stim[int(len(att_stim)/2):]\n",
    "        unatt_stim = unatt_stim[int(len(unatt_stim)/2):]\n",
    "    \n",
    "    # display(Audio(att_stim,rate=fs_audio))\n",
    "    # display(Audio(unatt_stim,rate=fs_audio))\n",
    "\n",
    "    # Load short audio at its native rate (22050 Hz)\n",
    "    short_audio = np.squeeze(att_stim)\n",
    "    short_sr = 22050\n",
    "    \n",
    "    # Resample short audio to match long audio's sampling rate\n",
    "    short_audio_resampled = librosa.resample(short_audio, orig_sr=short_sr, target_sr=long_sr)\n",
    "    \n",
    "    # Normalize both signals\n",
    "    long_audio = (long_audio - np.mean(long_audio)) / np.std(long_audio)\n",
    "    short_audio_resampled = (short_audio_resampled - np.mean(short_audio_resampled)) / np.std(short_audio_resampled)\n",
    "    \n",
    "    # Cross-correlation to find best match\n",
    "    correlation = correlate(long_audio, short_audio_resampled, mode='valid')\n",
    "    best_match_index = np.argmax(correlation)\n",
    "    end_index = best_match_index + len(short_audio_resampled)\n",
    "\n",
    "    print(f\"Best match found at index range: {best_match_index} to {end_index} (Corr: {np.max(correlation)})\")\n",
    "\n",
    "    att_surprisal = np.expand_dims(surprisal_feature[round((best_match_index/long_sr*128)):round((end_index/long_sr*128))],axis=0)\n",
    "\n",
    "    \n",
    "    # att_env = np.abs(hilbert(att_stim))\n",
    "    # unatt_env = np.abs(hilbert(unatt_stim))\n",
    "    \n",
    "    # duration_sec = len(att_env) / fs_audio\n",
    "    # n_target_samples = int(duration_sec * fs_eeg)\n",
    "    # att_env = np.expand_dims(resample(att_env, n_target_samples),axis=0)\n",
    "    \n",
    "    # duration_sec = len(unatt_env) / fs_audio\n",
    "    # n_target_samples = int(duration_sec * fs_eeg)\n",
    "    # unatt_env = np.expand_dims(resample(unatt_env, n_target_samples),axis=0)\n",
    "\n",
    "    music_eeg_all.append(data['eeg_data'])\n",
    "    music_att_surprisal_all.append(att_surprisal)\n",
    "    # music_att_env_all.append(att_env)\n",
    "    # music_unatt_env_all.append(unatt_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c010a40-7c8f-496f-9f68-cb655fdc28ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_eeg = np.concatenate(speech_eeg_all,axis=1).T\n",
    "# speech_stim_att = np.concatenate(speech_att_env_all,axis=1).T\n",
    "# speech_stim_unatt = np.concatenate(speech_unatt_env_all,axis=1).T\n",
    "speech_stim_unatt = np.concatenate(speech_unatt_surprisal_all,axis=1).T\n",
    "speech_eeg = zscore(speech_eeg, axis=0)\n",
    "# speech_stim_att = zscore(speech_stim_att, axis=0)\n",
    "speech_stim_unatt = zscore(speech_stim_unatt, axis=0)\n",
    "\n",
    "music_eeg = np.concatenate(music_eeg_all,axis=1).T\n",
    "# music_stim_att = np.concatenate(music_att_env_all,axis=1).T\n",
    "# music_stim_unatt = np.concatenate(music_unatt_env_all,axis=1).T\n",
    "music_stim_att = np.concatenate(music_att_surprisal_all,axis=1).T\n",
    "music_eeg = zscore(music_eeg, axis=0)\n",
    "music_stim_att = zscore(music_stim_att, axis=0)\n",
    "# music_stim_unatt = zscore(music_stim_unatt, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a5d274ec-1266-493b-999d-9305854a7530",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "Train: 0.229\n",
      "Attended Music: -0.106\n",
      "Unattended Music: 0.018\n",
      "Split 2\n",
      "Train: 0.218\n",
      "Attended Music: 0.155\n",
      "Unattended Music: -0.384\n",
      "Split 3\n",
      "Train: 0.222\n",
      "Attended Music: -0.007\n",
      "Unattended Music: -0.034\n",
      "Split 4\n",
      "Train: 0.149\n",
      "Attended Music: 0.163\n",
      "Unattended Music: -0.044\n",
      "Split 5\n",
      "Train: 0.214\n",
      "Attended Music: -0.033\n",
      "Unattended Music: -0.153\n",
      "Split 6\n",
      "Train: 0.227\n",
      "Attended Music: 0.046\n",
      "Unattended Music: -0.026\n",
      "Split 7\n",
      "Train: 0.236\n",
      "Attended Music: -0.035\n",
      "Unattended Music: 0.072\n",
      "Split 8\n",
      "Train: 0.25\n",
      "Attended Music: -0.08\n",
      "Unattended Music: 0.136\n",
      "Split 9\n",
      "Train: 0.249\n",
      "Attended Music: -0.114\n",
      "Unattended Music: -0.125\n",
      "Split 10\n",
      "Train: 0.22\n",
      "Attended Music: 0.189\n",
      "Unattended Music: 0.077\n",
      "Split 11\n",
      "Train: 0.235\n",
      "Attended Music: 0.114\n",
      "Unattended Music: -0.134\n",
      "Split 12\n",
      "Train: 0.232\n",
      "Attended Music: -0.051\n",
      "Unattended Music: -0.208\n",
      "Split 13\n",
      "Train: 0.219\n",
      "Attended Music: 0.046\n",
      "Unattended Music: -0.004\n",
      "Split 14\n",
      "Train: 0.225\n",
      "Attended Music: 0.066\n",
      "Unattended Music: -0.091\n",
      "Split 15\n",
      "Train: 0.224\n",
      "Attended Music: 0.041\n",
      "Unattended Music: 0.051\n",
      "Split 16\n",
      "Train: 0.228\n",
      "Attended Music: -0.143\n",
      "Unattended Music: -0.043\n",
      "Split 17\n",
      "Train: 0.221\n",
      "Attended Music: 0.032\n",
      "Unattended Music: -0.02\n",
      "Split 18\n",
      "Train: 0.223\n",
      "Attended Music: 0.106\n",
      "Unattended Music: 0.04\n",
      "Split 19\n",
      "Train: 0.225\n",
      "Attended Music: 0.067\n",
      "Unattended Music: 0.112\n",
      "Split 20\n",
      "Train: 0.22\n",
      "Attended Music: 0.056\n",
      "Unattended Music: -0.088\n",
      "Average Training Correlation: 0.22326349016721414\n",
      "Average Attended Music Test Correlation: 0.025633235703509272\n",
      "Average Unttended Music Test Correlation: -0.04245280189458196\n"
     ]
    }
   ],
   "source": [
    "train_corrs = []\n",
    "# speech_att_test_corrs = []\n",
    "speech_unatt_test_corrs = []\n",
    "music_att_test_corrs = []\n",
    "# music_unatt_test_corrs = []\n",
    "\n",
    "\n",
    "speech_sample_len = speech_eeg.shape[0]\n",
    "music_sample_len = music_eeg.shape[0]\n",
    "\n",
    "k_cv = 20\n",
    "for i in range(k_cv):\n",
    "    print(f'Split {i+1}')\n",
    "\n",
    "    #Train Test Split\n",
    "    \n",
    "    speech_eeg_test = speech_eeg[i*(round(speech_sample_len/k_cv)):(i+1)*(round(speech_sample_len/k_cv)),:]\n",
    "    # speech_stim_att_test = speech_stim_att[i*(round(speech_sample_len/k_cv)):(i+1)*(round(speech_sample_len/k_cv)),:]\n",
    "    speech_stim_unatt_test = speech_stim_unatt[i*(round(speech_sample_len/k_cv)):(i+1)*(round(speech_sample_len/k_cv)),:]\n",
    "\n",
    "    music_eeg_test = music_eeg[i*(round(music_sample_len/k_cv)):(i+1)*(round(music_sample_len/k_cv)),:]\n",
    "    music_stim_att_test = music_stim_att[i*(round(music_sample_len/k_cv)):(i+1)*(round(music_sample_len/k_cv)),:]\n",
    "    # music_stim_unatt_test = music_stim_unatt[i*(round(music_sample_len/k_cv)):(i+1)*(round(music_sample_len/k_cv)),:]\n",
    "\n",
    "    # speech_eeg_train = np.concatenate((speech_eeg[:i*(round(speech_sample_len/k_cv)),:],speech_eeg[(i+1)*(round(speech_sample_len/k_cv)):,:]),axis=0)\n",
    "    # speech_stim_train = np.concatenate((speech_stim_att[:i*(round(speech_sample_len/k_cv)),:],speech_stim_att[(i+1)*(round(speech_sample_len/k_cv)):,:]),axis=0)\n",
    "\n",
    "    music_eeg_train = np.concatenate((music_eeg[:i*(round(music_sample_len/k_cv)),:],music_eeg[(i+1)*(round(music_sample_len/k_cv)):,:]),axis=0)\n",
    "    music_stim_train = np.concatenate((music_stim_att[:i*(round(music_sample_len/k_cv)),:],music_stim_att[(i+1)*(round(music_sample_len/k_cv)):,:]),axis=0)\n",
    "\n",
    "    eeg_train = music_eeg_train\n",
    "    stim_train = music_stim_train\n",
    "    \n",
    "    #Lags\n",
    "    \n",
    "    eeg_train = lag_generator_new(eeg_train,lags_neuro)\n",
    "    stim_train = lag_generator_new(stim_train,lags_stim)\n",
    "    \n",
    "    speech_eeg_test = lag_generator_new(speech_eeg_test,lags_neuro)\n",
    "    # speech_stim_att_test = lag_generator_new(speech_stim_att_test,lags_stim)\n",
    "    speech_stim_unatt_test = lag_generator_new(speech_stim_unatt_test,lags_stim)\n",
    "\n",
    "    music_eeg_test = lag_generator_new(music_eeg_test,lags_neuro)\n",
    "    music_stim_att_test = lag_generator_new(music_stim_att_test,lags_stim)\n",
    "    # music_stim_unatt_test = lag_generator_new(music_stim_unatt_test,lags_stim)\n",
    "\n",
    "    #Training\n",
    "    \n",
    "    cca_att = CCA(n_components=3)\n",
    "    cca_att = cca_att.fit(eeg_train, stim_train)\n",
    "\n",
    "    #Evaluations\n",
    "    \n",
    "    X_c, Y_c = cca_att.transform(eeg_train, stim_train)\n",
    "    r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    print(f\"Train: {r_fwd.round(3)}\")\n",
    "    train_corrs.append(r_fwd)\n",
    "\n",
    "    # X_c, Y_c = cca_att.transform(speech_eeg_test, speech_stim_att_test)\n",
    "    # r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    # print(f\"Attended Speech: {r_fwd.round(3)}\")\n",
    "    # speech_att_test_corrs.append(r_fwd)\n",
    "    \n",
    "    # X_c, Y_c = cca_att.transform(music_eeg_test, music_stim_unatt_test)\n",
    "    # r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    # print(f\"Unattended Speech: {r_fwd.round(3)}\")\n",
    "    # music_unatt_test_corrs.append(r_fwd)\n",
    "\n",
    "    X_c, Y_c = cca_att.transform(music_eeg_test, music_stim_att_test)\n",
    "    r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    print(f\"Attended Music: {r_fwd.round(3)}\")\n",
    "    music_att_test_corrs.append(r_fwd)\n",
    "\n",
    "    X_c, Y_c = cca_att.transform(speech_eeg_test, speech_stim_unatt_test)\n",
    "    r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    print(f\"Unattended Music: {r_fwd.round(3)}\")\n",
    "    speech_unatt_test_corrs.append(r_fwd)\n",
    "\n",
    "\n",
    "print(f'Average Training Correlation: {np.mean(train_corrs)}')\n",
    "# print(f'Average Attended Speech Test Correlation: {np.mean(speech_att_test_corrs)}')\n",
    "# print(f'Average Unttended Speech Test Correlation: {np.mean(music_unatt_test_corrs)}')\n",
    "print(f'Average Attended Music Test Correlation: {np.mean(music_att_test_corrs)}')\n",
    "print(f'Average Unttended Music Test Correlation: {np.mean(speech_unatt_test_corrs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31e03fd5-2510-421f-ada6-723d29f04c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"Speech-Attended Music-Unattended AAD Accuracy: {np.mean([True if speech_att_test_corrs[i] > speech_unatt_test_corrs[i] else False for i in range(len(speech_att_test_corrs))])}\")\n",
    "# print(f\"Music-Attended Speech-Unattended AAD Accuracy: {np.mean([True if music_att_test_corrs[i] > music_unatt_test_corrs[i] else False for i in range(len(music_att_test_corrs))])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bc6530-3e8b-410a-8c79-46a21950ad43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Attended Music Test Correlation: 0.025633235703509272\n",
      "Std Attended Music Test Correlation: 0.0927111830522191\n",
      "Average Unattended Music Test Correlation: -0.04245280189458196\n",
      "Std Unattended Music Test Correlation: 0.11834964060506413\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Attended Music Test Correlation: {np.mean(music_att_test_corrs)}')\n",
    "print(f'Std Attended Music Test Correlation: {np.std(music_att_test_corrs)}')\n",
    "print(f'Average Unattended Music Test Correlation: {np.mean(speech_unatt_test_corrs)}')\n",
    "print(f'Std Unattended Music Test Correlation: {np.std(speech_unatt_test_corrs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e0499a0-7744-40de-9313-808b71495e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to disk\n",
    "# np.save('Weights/CCA_Multi_Music_Train_Envelope_X_Weights.npy', cca_att.x_weights_)\n",
    "# np.save('Weights/CCA_Multi_Music_Train_Envelope_Y_Weights.npy', cca_att.y_weights_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cu)",
   "language": "python",
   "name": "cu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
