{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a2dce67-417e-4516-976b-7f50e98e85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mtrf\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import zscore, pearsonr\n",
    "from scipy.signal import hilbert, resample, correlate\n",
    "\n",
    "from mtrf.model import TRF\n",
    "from sklearn.cross_decomposition import CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7187472f-7eee-4801-905e-e5c9bfcbfdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lag_generator_new(r, lags):\n",
    "    '''\n",
    "    Args:\n",
    "      r: [time, neurons]\n",
    "      \n",
    "    Return\n",
    "      out: [time, neuron*lags]\n",
    "    \n",
    "    '''\n",
    "    lags = list(range(lags[0], lags[1]+1))\n",
    "    out = np.zeros([r.shape[0], r.shape[1]*len(lags)])\n",
    "    r = np.pad(r, ((0,len(lags)),(0,0)), 'constant')\n",
    "\n",
    "    r_lag_list = []\n",
    "    \n",
    "    for lag in lags:\n",
    "        t1 = np.roll(r, lag, axis=0)\n",
    "        if lag < 0:\n",
    "            t1[lag-1:, :] = 0\n",
    "        else:\n",
    "            t1[:lag, :] = 0\n",
    "            \n",
    "        r_lag_list.append(t1[:out.shape[0], :])\n",
    "        \n",
    "    out = np.concatenate(r_lag_list, axis=1)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd95c8fe-bfbf-4ad7-97e7-a45c143d5dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = '../../../Data/Cindy/Preprocessed/single_filtered_01_15Hz'\n",
    "data_train1_speech = loadmat(os.path.join(folder_name,'cindy_single2_jane_eyre_05_part1.mat'))\n",
    "data_train2_speech = loadmat(os.path.join(folder_name,'cindy_single2_jane_eyre_05_part2.mat'))\n",
    "data_train1_music = loadmat(os.path.join(folder_name,'cindy_single2_piano_4_1_22050Hz.mat'))\n",
    "data_train2_music = loadmat(os.path.join(folder_name,'cindy_single2_piano_4_2_22050Hz.mat'))\n",
    "\n",
    "\n",
    "# folder_name = '../../../Data/Samet/Preprocessed/preprocessed_single_01_15Hz'\n",
    "# data_train1_speech = loadmat(os.path.join(folder_name,'single1_jane_eyre_05_part1.mat'))\n",
    "# data_train2_speech = loadmat(os.path.join(folder_name,'single3_jane_eyre_05_part2.mat'))\n",
    "# data_train1_music = loadmat(os.path.join(folder_name,'single2_piano_4_1_22050Hz.mat'))\n",
    "# data_train2_music = loadmat(os.path.join(folder_name,'single4_piano_4_2_22050Hz.mat'))\n",
    "\n",
    "fs_eeg = 128  # Sampling rate in Hz\n",
    "fs_audio = 22050\n",
    "\n",
    "lags_neuro = [-40, 10]\n",
    "lags_stim = [-10, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de9b4ad9-4921-4ba1-a1fc-bb66798c656f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best match found at index range: 0 to 28951030 (Corr: 34864052.0)\n",
      "Best match found at index range: 84147472 to 108461328 (Corr: 933777.375)\n"
     ]
    }
   ],
   "source": [
    "# Load long audio at 1000 Hz\n",
    "long_audio, long_sr = librosa.load(f'../../../Stimuli/Cindy/piano_4.wav', sr=None)\n",
    "\n",
    "# Load short audio at its native rate (22050 Hz)\n",
    "short_audio = np.squeeze(data_train1_music['stimuli'])\n",
    "short_sr = 22050\n",
    "\n",
    "# Resample short audio to match long audio's sampling rate\n",
    "short_audio_resampled = librosa.resample(short_audio, orig_sr=short_sr, target_sr=long_sr)\n",
    "\n",
    "# Normalize both signals\n",
    "long_audio = (long_audio - np.mean(long_audio)) / np.std(long_audio)\n",
    "short_audio_resampled = (short_audio_resampled - np.mean(short_audio_resampled)) / np.std(short_audio_resampled)\n",
    "\n",
    "# Cross-correlation to find best match\n",
    "correlation = correlate(long_audio, short_audio_resampled, mode='valid')\n",
    "best_match_index1 = np.argmax(correlation)\n",
    "end_index1 = best_match_index1 + len(short_audio_resampled)\n",
    "\n",
    "print(f\"Best match found at index range: {best_match_index1} to {end_index1} (Corr: {np.max(correlation)})\")\n",
    "\n",
    "# Load short audio at its native rate (22050 Hz)\n",
    "short_audio = np.squeeze(data_train2_music['stimuli'])\n",
    "short_sr = 22050\n",
    "\n",
    "# Resample short audio to match long audio's sampling rate\n",
    "short_audio_resampled = librosa.resample(short_audio, orig_sr=short_sr, target_sr=long_sr)\n",
    "\n",
    "# Normalize both signals\n",
    "long_audio = (long_audio - np.mean(long_audio)) / np.std(long_audio)\n",
    "short_audio_resampled = (short_audio_resampled - np.mean(short_audio_resampled)) / np.std(short_audio_resampled)\n",
    "\n",
    "# Cross-correlation to find best match\n",
    "correlation = correlate(long_audio, short_audio_resampled, mode='valid')\n",
    "best_match_index2 = np.argmax(correlation)\n",
    "end_index2 = best_match_index2 + len(short_audio_resampled)\n",
    "\n",
    "print(f\"Best match found at index range: {best_match_index2} to {end_index2} (Corr: {np.max(correlation)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16996a8e-9e5e-4fee-9031-ebb71a2cfe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: EEG shape = [n_channels, n_samples]\n",
    "#          Stimulus shape = [1, n_samples]\n",
    "\n",
    "# Load your data (replace with your real data)\n",
    "eeg1 = data_train1_music['eeg_data'].T\n",
    "# stim1 = data_train1_speech['envelope'].T\n",
    "# eeg1 = eeg1[:stim1.shape[0],:]\n",
    "# stim1 = stim1[:eeg1.shape[0],:]\n",
    "eeg1 = zscore(eeg1, axis=0)\n",
    "\n",
    "\n",
    "eeg2 = data_train2_music['eeg_data'].T[:-1,:]\n",
    "# stim2 = data_train2_speech['envelope'].T\n",
    "# eeg2 = eeg2[:stim2.shape[0],:]\n",
    "#stim2 = stim2[:eeg2.shape[0],:]\n",
    "eeg2 = zscore(eeg2, axis=0)\n",
    "\n",
    "surprisal_feature = pd.read_csv('../../../Stimuli/Cindy/Surprisal/piano_4.csv')\n",
    "surprisal_feature = np.array(surprisal_feature['surprise'].to_list())\n",
    "\n",
    "\n",
    "# stim1 = np.expand_dims(surprisal_feature[0:eeg1.shape[0]],axis=1)\n",
    "# stim2 = np.expand_dims(surprisal_feature[eeg1.shape[0]:eeg1.shape[0]+eeg2.shape[0]],axis=1)\n",
    "stim1 = np.expand_dims(surprisal_feature[round((best_match_index1/long_sr*128)):round((end_index1/long_sr*128))],axis=1)\n",
    "# stim2 = np.expand_dims(surprisal_feature[round((best_match_index2/long_sr*128)):round((end_index2/long_sr*128))],axis=1)\n",
    "stim2 = np.expand_dims(surprisal_feature[round((best_match_index2/long_sr*128)):round((best_match_index2/long_sr*128))+eeg2.shape[0]],axis=1)\n",
    "\n",
    "# stim1 = np.squeeze(data_train1_music['stimuli'])\n",
    "# stim1 = np.abs(hilbert(stim1))\n",
    "# duration_sec = len(stim1) / fs_audio\n",
    "# n_target_samples = int(duration_sec * fs_eeg)\n",
    "# stim1 = np.expand_dims(resample(stim1, n_target_samples),axis=1)\n",
    "# stim1 = zscore(stim1, axis=0)\n",
    "\n",
    "# stim2 = np.squeeze(data_train2_music['stimuli'])\n",
    "# stim2 = np.abs(hilbert(stim2))\n",
    "# duration_sec = len(stim2) / fs_audio\n",
    "# n_target_samples = int(duration_sec * fs_eeg)\n",
    "# stim2 = np.expand_dims(resample(stim2, n_target_samples),axis=1)\n",
    "# stim2 = zscore(stim2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86932895-bf40-4a82-9c4a-8925b93f0944",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eeg1.shape[0] > stim1.shape[0]:\n",
    "    eeg1 = eeg1[:stim1.shape[0],:]\n",
    "\n",
    "if eeg2.shape[0] > stim2.shape[0]:\n",
    "    eeg2 = eeg2[:stim2.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61c01ba3-7e91-4ba3-9d8f-da99e8918644",
   "metadata": {},
   "outputs": [],
   "source": [
    "eeg = np.concatenate((eeg1,eeg2),axis=0)\n",
    "stim = np.concatenate((stim1,stim2),axis=0)\n",
    "\n",
    "# eeg = eeg2\n",
    "# stim = stim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "922f33b4-dae4-4a5e-a29e-a271c3dacf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154404, 31)\n",
      "(154404, 1)\n"
     ]
    }
   ],
   "source": [
    "print(eeg.shape)\n",
    "print(stim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b052b615-987c-4734-8fba-162f8aa498f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "Train: 0.227\n",
      "Test: 0.166\n",
      "Split 2\n",
      "Train: 0.234\n",
      "Test: 0.137\n",
      "Split 3\n",
      "Train: 0.232\n",
      "Test: 0.128\n",
      "Split 4\n",
      "Train: 0.229\n",
      "Test: 0.095\n",
      "Split 5\n",
      "Train: 0.233\n",
      "Test: 0.149\n",
      "Split 6\n",
      "Train: 0.243\n",
      "Test: 0.031\n",
      "Split 7\n",
      "Train: 0.242\n",
      "Test: 0.063\n",
      "Split 8\n",
      "Train: 0.243\n",
      "Test: 0.053\n",
      "Split 9\n",
      "Train: 0.24\n",
      "Test: 0.086\n",
      "Split 10\n",
      "Train: 0.244\n",
      "Test: 0.02\n",
      "Average Training Correlation: 0.23685525905058458\n",
      "Average Test Correlation: 0.09288106768013096\n"
     ]
    }
   ],
   "source": [
    "sample_len = eeg.shape[0]\n",
    "\n",
    "train_corrs = []\n",
    "test_corrs = []\n",
    "\n",
    "k_cv = 10\n",
    "for i in range(k_cv):\n",
    "    print(f'Split {i+1}')\n",
    "    \n",
    "    eeg_train = np.concatenate((eeg[:i*(round(sample_len/k_cv)),:],eeg[(i+1)*(round(sample_len/k_cv)):,:]),axis=0)\n",
    "    stim_train = np.concatenate((stim[:i*(round(sample_len/k_cv)),:],stim[(i+1)*(round(sample_len/k_cv)):,:]),axis=0)\n",
    "    \n",
    "    eeg_test = eeg[i*(round(sample_len/k_cv)):(i+1)*(round(sample_len/k_cv)),:]\n",
    "    stim_test = stim[i*(round(sample_len/k_cv)):(i+1)*(round(sample_len/k_cv)),:]\n",
    "\n",
    "    eeg_train = lag_generator_new(eeg_train,lags_neuro)\n",
    "    eeg_test = lag_generator_new(eeg_test,lags_neuro)\n",
    "    stim_train = lag_generator_new(stim_train,lags_stim)\n",
    "    stim_test = lag_generator_new(stim_test,lags_stim)\n",
    "\n",
    "    cca_att = CCA(n_components=1)\n",
    "    cca_fit = cca_att.fit(eeg_train, stim_train)\n",
    "\n",
    "    X_c, Y_c = cca_fit.transform(eeg_train, stim_train)\n",
    "    r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    print(f\"Train: {r_fwd.round(3)}\")\n",
    "\n",
    "    train_corrs.append(r_fwd)\n",
    "\n",
    "    X_c, Y_c = cca_fit.transform(eeg_test, stim_test)\n",
    "    r_fwd = pearsonr(np.squeeze(X_c.flatten()), np.squeeze(Y_c.flatten())).statistic\n",
    "    print(f\"Test: {r_fwd.round(3)}\")\n",
    "\n",
    "    test_corrs.append(r_fwd)\n",
    "\n",
    "print(f'Average Training Correlation: {np.mean(train_corrs)}')\n",
    "print(f'Average Test Correlation: {np.mean(test_corrs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1171d969-59a6-4e28-8c2d-9352b6e2dade",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Correlation: 0.09288106768013096\n",
      "Std Test Correlation: 0.04836690864628974\n"
     ]
    }
   ],
   "source": [
    "print(f'Average Test Correlation: {np.mean(test_corrs)}')\n",
    "print(f'Std Test Correlation: {np.std(test_corrs)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cu)",
   "language": "python",
   "name": "cu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
